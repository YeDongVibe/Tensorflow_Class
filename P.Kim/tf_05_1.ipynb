{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Chapter05 완전 연결 신경망 분류(Classification)\n",
        "\n",
        "15 원-핫 인코딩과 교차 엔트로피 오차\n",
        "\n",
        "16 활성화 함수\n",
        "\n",
        "17 분류 성능평가\n",
        "\n",
        "18 1-Dense 층(1뉴런) AND?OR 분류\n",
        "\n",
        "19 1-Dense 층(2뉴런) AND?OR 분류\n",
        "\n",
        "20 2층 신경망: XOR 이진 분류\n",
        "\n",
        "21 2D 정규분포 데이터 생성 및 분류\n",
        "\n",
        "22 IRIS 데이터 분류"
      ],
      "metadata": {
        "id": "QLUlswTz3vtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Prerequisite"
      ],
      "metadata": {
        "id": "wi0eCU_gMukI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://research.google.com/colaboratory/local-runtimes.html"
      ],
      "metadata": {
        "id": "kUpvlJ83M0bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "id": "gGMWEuNXMv2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IwyJD6H2nD60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 16. Activation Function"
      ],
      "metadata": {
        "id": "7U0KO1Z1iLR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* 우리 뇌의 뉴런은 임계치를 넘는 신호가 들어오면 출력함\n",
        "* <a href=\"https://uploads-ssl.webflow.com/614c82ed388d53640613982e/64a6b855e23a0a3dff98bfa0_linear%20and%20non%20linear%20functions.webp\">nonlinear</a>: 복잡한 표현을 학습하기 위해 필요\n",
        "* 그렇지 않으면, 결국 레이어 하나로 표현 가능해짐\n",
        "* weighted sum -> activation 함수의 입력 값\n",
        "\n",
        "$$ Weighted\\ Sum = \\sum_{i=1}^nx_iW_i + b$$"
      ],
      "metadata": {
        "id": "4kxE2lofoyin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uzraphxv6aozpVYbqYYAVw.jpeg\" width=800 />\n"
      ],
      "metadata": {
        "id": "cGlwyjBamTtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]], dtype = np.float32)\n",
        "y_true = np.array([[0],[0],[0],[1]], dtype = np.float32)   # AND\n",
        "X, y_true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifQiJsSJnD62",
        "outputId": "1d999461-7b00-4740-d2d0-572deea1f6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 1.]], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "# activation=tf.keras.activations.sigmoid\n",
        "# sigmoid, tanh, relu, softmax\n",
        "model.add(tf.keras.layers.Dense(units=1, input_dim=2, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7658779b-20fd-48b3-c215-705886a4b3d1",
        "id": "uPNBPw3KnD63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a04iKNbchayCAJ7-0QlesA.png\" width=400/>"
      ],
      "metadata": {
        "id": "C66dwglqve_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### sigmoid\n",
        "\n",
        "* 미분 가능함\n",
        "* <a href=\"https://upload.wikimedia.org/wikipedia/commons/d/dc/Exponenciala_priklad.png\">지수함수</a>로 (0, 1) 사이의 값 (마치 확률처럼)\n",
        "* 함수값이 (0, 1) 값이므로 <a href=\"https://uploads-ssl.webflow.com/614c82ed388d53640613982e/64a7fb7b268ea3f26d08b456_vanishing-and-exploding-gradients.webp\">exploding</a> 안됨\n",
        "* but, <a href=\"https://uploads-ssl.webflow.com/614c82ed388d53640613982e/64a7fb7b268ea3f26d08b456_vanishing-and-exploding-gradients.webp\">vanishing gradient</a> 문제가 있음\n",
        "* weights sum 값이 -100이나 100인 경우 gradient가 거의 0에 가까워서 saturated neurons 은 거의 변경되지 않음\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a9q9rdIHePiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient vanishing, exploding, saturation problem\n",
        "\n",
        "<img src=\"https://global-uploads.webflow.com/5ef788f07804fb7d78a4127a/6245a9aca7defe61cea5ea7d_Engati-vanishing-point-problem.jpg\" width=400><img src=\"https://miro.medium.com/max/1178/1*54WxyNRIoO6OX8Jwa-caeQ.webp\" width=400>\n",
        "\n",
        "\n",
        "\n",
        "* gradient vanishing problem, 미분값 최대 0.25,\n",
        "* layer가 7층인 경우, $0.25^7 = 0.000061035 $\n"
      ],
      "metadata": {
        "id": "VU_2UqHrBKfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/max/1400/1*ZafDv3VUm60Eh10OeJu1vw.webp\" width=800 />"
      ],
      "metadata": {
        "id": "YawQ7NZgvL6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tanh\n",
        "\n",
        "* scaled sigmoid function\n",
        "* 함수값이 (-1,1) 사이고, (0,0) 에서 대칭\n",
        "* RNN, LSTM\n",
        "\n",
        "### relu (hinton, 2010)\n",
        "\n",
        "* vanishing gradient 문제를 해결하고자 고안 (z 값이 0 보다 크면 미분값이 1임)\n",
        "* 함수값은 max(0, z)\n",
        "* 가장 널리 사용됨 (특히 큰 규모의 모델에서)\n",
        "* 계산이 빠름\n",
        "* but, [0, 무한대) 범위, 양수값이 너무 커서 exploding 될 수 있음\n",
        "* relu 는 마이너스에서 미분 불가\n",
        "* weight sum 값이 마이너스이면 0 이 됨 => dying ReLU 문제 (미분값이 없으므로, weight 초기값에 변화가 없음)\n",
        "\n",
        "\n",
        "### leaky relu(2013)\n",
        "\n",
        "* relu 가 마이너스에서 미분되지 않는 단점을 보완\n",
        "* max(0.1z, z)"
      ],
      "metadata": {
        "id": "6I8e9HkFskbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### softmax\n",
        "\n",
        "* 주로 분류(classification) 모델의 마지막 계층의 활성화 함수로 사용됨\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f3bU5PP0sIsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Nabi-Nabiyev-2/publication/349662206/figure/fig3/AS:995882686246913@1614448343589/Working-principles-of-softmax-function.jpg\" width=400/>"
      ],
      "metadata": {
        "id": "qWdpnKuWi4Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ softmax(z) = \\frac{{e^{z_{j}}}}{\\Sigma_{n=1}^{n}{e^{z_{n}}}}, (for \\ j=1, 2, ...n)$$\n",
        "\n",
        "* 큰 값을 강조하고 작은 값을 약화시키는 효과\n",
        "* 0 이나 음수에도 적용 가능\n",
        "* 결과값으로 확률이 필요한 경우 사용 (classification 등)"
      ],
      "metadata": {
        "id": "_GkUtNLhjCzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#z=tf.random.normal(shape=(1,3))\n",
        "z=[2.,1,0]\n",
        "z=tf.reshape(z, shape=(1,3))\n",
        "print('z', z)\n",
        "\n",
        "softmax_output=tf.keras.activations.softmax(z)\n",
        "print('softmax_output', softmax_output)\n",
        "\n",
        "# sigmoid_output=tf.keras.activations.sigmoid(z)\n",
        "# print('sigmoid_output', sigmoid_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnetuZIGZh5r",
        "outputId": "7f731d4b-c515-4a97-c6bc-befee0ed607e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z tf.Tensor([[2. 1. 0.]], shape=(1, 3), dtype=float32)\n",
            "softmax_output tf.Tensor([[0.66524094 0.24472848 0.09003057]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x = tf.constant([-10, -1.0, 0.0, 1.0, 10], dtype = tf.float32)\n",
        "\n",
        "y1 = tf.keras.activations.linear(x)\n",
        "y2 = tf.keras.activations.sigmoid(x)\n",
        "y3 = tf.keras.activations.tanh(x)\n",
        "y4 = tf.keras.activations.relu(x)\n",
        "y5 = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
        "y6 = tf.keras.activations.softmax(tf.reshape(x, shape=(1, -1)))\n",
        "\n",
        "print(\"y1=\", y1.numpy())\n",
        "print(\"y2=\", y2.numpy())\n",
        "print(\"y3=\", y3.numpy())\n",
        "print(\"y4=\", y4.numpy())\n",
        "print(\"y5=\", y5.numpy())\n",
        "print(\"y6=\", y6.numpy())\n",
        "print(\"sum(y6)=\", np.sum(y6.numpy())) # 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oySEppa4phq",
        "outputId": "0fb3b7a1-d671-4a1e-c397-0f9267e0d182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y1= [-10.  -1.   0.   1.  10.]\n",
            "y2= [4.5397868e-05 2.6894143e-01 5.0000000e-01 7.3105860e-01 9.9995458e-01]\n",
            "y3= [-1.        -0.7615942  0.         0.7615942  1.       ]\n",
            "y4= [ 0.  0.  0.  1. 10.]\n",
            "y5= [-1.  -0.1  0.   1.  10. ]\n",
            "y6= [[2.0607716e-09 1.6698603e-05 4.5391513e-05 1.2338691e-04 9.9981457e-01]]\n",
            "sum(y6)= 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 15. One-hot encoding"
      ],
      "metadata": {
        "id": "8ReLwsAwW5Yy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "숫자가 아닌 데이터([개, 고양이], 문자열 - \"이것을 강력 추천합니다\" 등) 를 모델의 입력으로 사용하려면 숫자로 변경해야 함"
      ],
      "metadata": {
        "id": "64xI7jaobYJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### why one-hot encoding?\n",
        "\n",
        "개, 고양이, 토끼를 각각 1,2,3 으로 인코딩 하면,\n",
        "\n",
        "* 토끼가 가장 중요한 값인가?\n",
        "\n",
        "* 개와 토끼의 평균은 고양이인가?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-BcwN0G2Z-ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### when should not use?\n",
        "\n",
        "* 카테고리 값이 50개이면, 새로운 컬럼 50개가 추가됨\n",
        "\n",
        "* 남 10, 여 01 로 one-hot 인코딩하면, 두 컬럼 사이에 강한 상관 관계가 발생함 (남 컬럼이 1이면, 무조건 여 컬럼은 0임)\n",
        "\n",
        "| 원래 컬럼   |   남 컬럼      |  여 컬럼 |\n",
        "|----------|:-------------:|------:|\n",
        "| 남자 |  1 | 0 |\n",
        "| 여자 |  0 | 1 |\n",
        "| 남자 |  1 | 0 |\n"
      ],
      "metadata": {
        "id": "znn1qGpFbKM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## p.113"
      ],
      "metadata": {
        "id": "Vci-lSn1XfaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "y = range(2) # integer label\n",
        "print(\"y=\", list(y))\n",
        "\n",
        "y = np.arange(2)\n",
        "y1 = tf.keras.utils.to_categorical(y) # keras one-hot label\n",
        "print(\"y1=\", y1)\n",
        "\n",
        "y2 = tf.keras.utils.to_categorical([1, 2, 3, 0, 2], num_classes=4)\n",
        "print(\"y2=\", y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpnfJpD1XIse",
        "outputId": "e7571ee5-c31f-4b3f-dcfd-cb0167b16299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y= [0, 1]\n",
            "y1= [[1. 0.]\n",
            " [0. 1.]]\n",
            "y2= [[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Categorical Cross-Entropy Loss\n",
        "\n",
        "https://en.wikipedia.org/wiki/Entropy_%28information_theory%29\n",
        "\n",
        "> In information theory, the entropy of a random variable is the average level of \"information\", \"surprise\", or \"uncertainty\" inherent to the variable's possible outcomes.\n",
        "\n",
        "\n",
        "$$ Entropy(x) = log \\frac{1}{softmax(x)} = -log(softmax(x)) $$\n",
        "\n",
        "<br>\n",
        "\n",
        "$$ Entropy의\\ 기대값 (x) = 확률(Y\\_label)에\\ 엔트로피를\\ 곱한\\ 값 \\\\\n",
        "즉,\\ E(엔트로피)\\ =\\ -확률(Y\\_label)\\ log(softmax(x)) $$\n",
        "\n",
        "* 엔트로피는 불확실성이 높으면 값이 높음\n",
        "* 엔트로피는 확률의 역수에 로그를 취한 값\n",
        "* 확률의 역수를 취하는 이유는 확률이 높은 사건일수록 정보량(놀라움, 불확실성)이 낮다고 판단\n",
        "* loss 로 사용 시 엔트로피 값 (불확실성) 을 낮추는 방향으로 학습\n",
        "\n",
        "\n",
        "$$ CCE = -\\frac{1}{n}\\Sigma_{i=1}^nE(x)$$\n",
        "\n"
      ],
      "metadata": {
        "id": "0bJ6Xg66fDJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_output=[[0.87, 0.13], [0.6, 0.4]]\n",
        "entropy=tf.math.log(softmax_output)\n",
        "print('entropy', entropy)\n",
        "\n",
        "y_label=tf.keras.utils.to_categorical([0,1], num_classes=2)\n",
        "print('y_label', y_label)\n",
        "\n",
        "E_entropy = -1/2*(y_label * entropy)\n",
        "print('E_entropy', E_entropy)\n",
        "\n",
        "CCE = tf.reduce_sum(E_entropy)\n",
        "print('CCE', CCE)\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy()(y_label, softmax_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE1vYPdWfHfV",
        "outputId": "a25973fa-4347-4bbb-dedc-a5afa026c69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entropy tf.Tensor(\n",
            "[[-0.13926207 -2.040221  ]\n",
            " [-0.5108256  -0.9162907 ]], shape=(2, 2), dtype=float32)\n",
            "y_label [[1. 0.]\n",
            " [0. 1.]]\n",
            "E_entropy tf.Tensor(\n",
            "[[0.06963103 0.        ]\n",
            " [0.         0.45814535]], shape=(2, 2), dtype=float32)\n",
            "CCE tf.Tensor(0.52777636, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.52777636>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CategoricalCrossentropy"
      ],
      "metadata": {
        "id": "85i_kuhz4eAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "CCE = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# one-hot encoding\n",
        "y_label= np.array([[1,   0,   0,   0],   #t[0]\n",
        "             [0,   1,   0,   0],   #t[1]\n",
        "             [0,   0,   1,   0],   #t[2]\n",
        "             [0,   0,   0,   1]])  #t[3]\n",
        "\n",
        "# softmax output\n",
        "z =np.array([[0.4, 0.3, 0.2, 0.1], #y[0]\n",
        "             [0.1, 0.3, 0.2, 0.4]])#y[1]\n",
        "\n",
        "#1\n",
        "print(\"CCE(t[i], y[0])\")\n",
        "print(\"CCE(t[0], y[0])=\", CCE(y_label[0], z[0]).numpy() )\n",
        "print(\"CCE(t[1], y[0])=\", CCE(y_label[1], z[0]).numpy() )\n",
        "print(\"CCE(t[2], y[0])=\", CCE(y_label[2], z[0]).numpy() )\n",
        "print(\"CCE(t[3], y[0])=\", CCE(y_label[3], z[0]).numpy() )\n",
        "\n",
        "#2\n",
        "print(\"CCE(t[i], y[1])\")\n",
        "print(\"CCE(t[0], y[1])=\", CCE(y_label[0], z[1]).numpy() )\n",
        "print(\"CCE(t[1], y[1])=\", CCE(y_label[1], z[1]).numpy() )\n",
        "print(\"CCE(t[2], y[1])=\", CCE(y_label[2], z[1]).numpy() )\n",
        "print(\"CCE(t[3], y[1])=\", CCE(y_label[3], z[1]).numpy() )\n",
        "\n",
        "#3\n",
        "print(\"CCE(np.vstack((t[1], t[1])), y)=\",\n",
        "       CCE(np.vstack((y_label[0], y_label[1])), z).numpy() )\n",
        "\n",
        "(0.916290731874155 + 1.203972804325936) / 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTF4WzyX1lN_",
        "outputId": "74524bcd-c747-487f-c40f-b8df63a2daef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CCE(t[i], y[0])\n",
            "CCE(t[0], y[0])= 0.916290731874155\n",
            "CCE(t[1], y[0])= 1.203972804325936\n",
            "CCE(t[2], y[0])= 1.6094379124341003\n",
            "CCE(t[3], y[0])= 2.3025850929940455\n",
            "CCE(t[i], y[1])\n",
            "CCE(t[0], y[1])= 2.3025850929940455\n",
            "CCE(t[1], y[1])= 1.203972804325936\n",
            "CCE(t[2], y[1])= 1.6094379124341003\n",
            "CCE(t[3], y[1])= 0.916290731874155\n",
            "CCE(np.vstack((t[1], t[1])), y)= 1.0601317681000455\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0601317681000455"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "Y1AlMh2j4fX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "SCE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# label encoding\n",
        "t = tf.convert_to_tensor([0, 1, 2, 3])\n",
        "\n",
        "# softmax output\n",
        "y =tf.convert_to_tensor([[0.4, 0.3, 0.2, 0.1], #y[0]\n",
        "                         [0.1, 0.3, 0.2, 0.4]])#y[1]\n",
        "\n",
        "#1\n",
        "print(\"SCE(t[i], y[0])\")\n",
        "print(\"SCE(t[0], y[0])=\", SCE(t[0], y[0]).numpy() )\n",
        "print(\"SCE(t[1], y[0])=\", SCE(t[1], y[0]).numpy() )\n",
        "print(\"SCE(t[2], y[0])=\", SCE(t[2], y[0]).numpy() )\n",
        "print(\"SCE(t[3], y[0])=\", SCE(t[3], y[0]).numpy() )\n",
        "\n",
        "#2\n",
        "print(\"SCE(t[i], y[1])\")\n",
        "print(\"SCE(t[0], y[1])=\", SCE(t[0], y[1]).numpy() )\n",
        "print(\"SCE(t[1], y[1])=\", SCE(t[1], y[1]).numpy() )\n",
        "print(\"SCE(t[2], y[1])=\", SCE(t[2], y[1]).numpy() )\n",
        "print(\"SCE(t[3], y[1])=\", SCE(t[3], y[1]).numpy() )\n",
        "\n",
        "#3\n",
        "print(\"SCE(tf.stack((t[1], t[1])), y)=\",\n",
        "       SCE(tf.stack((t[0], t[1])), y).numpy() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIejuJFa3WNX",
        "outputId": "cae393a5-1d0a-44a2-bef3-9ca9740e9bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCE(t[i], y[0])\n",
            "SCE(t[0], y[0])= 0.91629076\n",
            "SCE(t[1], y[0])= 1.2039728\n",
            "SCE(t[2], y[0])= 1.609438\n",
            "SCE(t[3], y[0])= 2.3025851\n",
            "SCE(t[i], y[1])\n",
            "SCE(t[0], y[1])= 2.3025851\n",
            "SCE(t[1], y[1])= 1.2039728\n",
            "SCE(t[2], y[1])= 1.609438\n",
            "SCE(t[3], y[1])= 0.91629076\n",
            "SCE(tf.stack((t[1], t[1])), y)= 1.0601318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BinaryCrossentropy"
      ],
      "metadata": {
        "id": "uSdUzpUG4hlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "BCE = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# one-hot encoding\n",
        "t= np.array([[1,   0,   0,   0],   #t[0]\n",
        "             [0,   1,   0,   0],   #t[1]\n",
        "             [0,   0,   1,   0],   #t[2]\n",
        "             [0,   0,   0,   1]])  #t[3]\n",
        "\n",
        "# softmax output\n",
        "y =np.array([[0.4, 0.3, 0.2, 0.1], #y[0]\n",
        "             [0.1, 0.3, 0.2, 0.4]])#y[1]\n",
        "\n",
        "#1\n",
        "print(\"BCE(t[i], y[0])\")\n",
        "print(\"BCE(t[0], y[0])=\", BCE(t[0], y[0]).numpy() )\n",
        "print(\"BCE(t[1], y[0])=\", BCE(t[1], y[0]).numpy() )\n",
        "print(\"BCE(t[2], y[0])=\", BCE(t[2], y[0]).numpy() )\n",
        "print(\"BCE(t[3], y[0])=\", BCE(t[3], y[0]).numpy() )\n",
        "\n",
        "#2\n",
        "print(\"BCE(t[i], y[1])\")\n",
        "print(\"BCE(t[0], y[1])=\", BCE(t[0], y[1]).numpy() )\n",
        "print(\"BCE(t[1], y[1])=\", BCE(t[1], y[1]).numpy() )\n",
        "print(\"BCE(t[2], y[1])=\", BCE(t[2], y[1]).numpy() )\n",
        "print(\"BCE(t[3], y[1])=\", BCE(t[3], y[1]).numpy() )\n",
        "\n",
        "#3\n",
        "print(\"BCE(np.vstack((t[0], t[0])), y)=\",\n",
        "       BCE(np.vstack((t[0], t[0])), y).numpy() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyOOrZ-24NEG",
        "outputId": "2a4d19dc-e2cf-4e72-f39f-22b72e343ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCE(t[i], y[0])\n",
            "BCE(t[0], y[0])= 0.4003672784541813\n",
            "BCE(t[1], y[0])= 0.5108254397382338\n",
            "BCE(t[2], y[0])= 0.6455745187904711\n",
            "BCE(t[3], y[0])= 0.8483069443724252\n",
            "BCE(t[i], y[1])\n",
            "BCE(t[0], y[1])= 0.8483069443724252\n",
            "BCE(t[1], y[1])= 0.5108254397382338\n",
            "BCE(t[2], y[1])= 0.6455745187904711\n",
            "BCE(t[3], y[1])= 0.40036727845418124\n",
            "BCE(np.vstack((t[0], t[0])), y)= 0.6243371114133032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결론적으로 ..."
      ],
      "metadata": {
        "id": "n9R6_41a_ylR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=1, input_dim=2, activation='softmax'))\n",
        "model.summary()\n",
        "# cross-entropy loss for binary (0 or 1) classification\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# labels to be provided in a one_hot representation\n",
        "# y_label = [[0, 1, 0], [1, 0, 0]]\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=3, input_dim=2, activation='softmax'))\n",
        "model.summary()\n",
        "# two or more label classes, one_hot representation\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# labels as integers\n",
        "# y_label = [1, 2]\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=3, input_dim=2, activation='softmax'))\n",
        "model.summary()\n",
        "# two or more label classes, labels as integers\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1DFV8y__0Kc",
        "outputId": "909f0fcd-3c26-4d91-d1b0-5efc723b5d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 17. tf.keras.metrics for classification"
      ],
      "metadata": {
        "id": "rzsuhTyi1YL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\" width=400/><img src=\"https://1.bp.blogspot.com/-b_lbkGbwKCo/W-lK6MZ3-xI/AAAAAAAAAYA/uuAkY-KkyEAdSJPxJKRaam0qQoMo9wZ4ACLcBGAs/s1600/2.PNG\" width=400/>\n",
        "\n"
      ],
      "metadata": {
        "id": "DRozi4iD5i_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결론적으로 ..."
      ],
      "metadata": {
        "id": "mb-t1-669jeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=1, input_dim=2, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "QAW6FEmG9h5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### metrics=['accuracy']"
      ],
      "metadata": {
        "id": "vkguwJPA9l2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'f1_score'])"
      ],
      "metadata": {
        "id": "zDVP9dCC9Xd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_true=\",y_true)\n",
        "print(\"y_pred=\",y_pred)\n",
        "C = tf.math.confusion_matrix(y_true, y_pred)\n",
        "print(\"confusion_matrix(C)=\", C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQy9LhvM8xnf",
        "outputId": "15e95dfa-62e9-45c2-e5ca-56bcf265352d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_true= [1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1]\n",
            "y_pred= [0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1]\n",
            "confusion_matrix(C)= tf.Tensor(\n",
            "[[9 3]\n",
            " [3 3]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "#5-1\n",
        "m = tf.keras.metrics.TruePositives()\n",
        "m.update_state(y_true, y_pred)\n",
        "tp = m.result()  # m.true_positives\n",
        "print(\"tp =\", tp.numpy())\n",
        "\n",
        "#5-2\n",
        "m = tf.keras.metrics.TrueNegatives()\n",
        "m.update_state(y_true, y_pred)\n",
        "tn = m.result() # m.accumulator[0]\n",
        "print(\"tn=\", tn.numpy())\n",
        "\n",
        "#5-3\n",
        "m = tf.keras.metrics.FalsePositives()\n",
        "m.update_state(y_true, y_pred)\n",
        "fp = m.result() # m.accumulator[0] sms\n",
        "print(\"fp=\", fp.numpy())\n",
        "\n",
        "#5-4\n",
        "m = tf.keras.metrics.FalseNegatives()\n",
        "m.update_state(y_true, y_pred)\n",
        "fn = m.result()# m.accumulator[0]\n",
        "print(\"fn=\", fn.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUPtKzwG89Qx",
        "outputId": "16ed9cc2-cd03-45ae-a50e-f8579a00d9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tp = 3.0\n",
            "tn= 9.0\n",
            "fp= 3.0\n",
            "fn= 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy4  = (tp + tn)/(tp+tn+fp+fn)\n",
        "precision = tp/(tp+fp)\n",
        "recall    = tp/(tp+fn)\n",
        "f1 = 2*tp/(2*tp + fp + fn) # harmonic mean of precision and recall\n",
        "print(\"accuracy4 =\", accuracy4.numpy())\n",
        "print(\"precision =\",precision.numpy())\n",
        "print(\"recall =\",   recall.numpy())\n",
        "print(\"f1 score =\", f1.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjMN8sNA9E_D",
        "outputId": "0460b4c0-9e8a-4c72-dd83-95075265689a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy4 = 0.6666667\n",
            "precision = 0.5\n",
            "recall = 0.5\n",
            "f1 score = 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4:\n",
        "m = tf.keras.metrics.Accuracy()\n",
        "m.update_state(y_true, y_pred)\n",
        "print(\"m.total={}, m.count={}\".format(m.total.numpy(), m.count.numpy()))\n",
        "accuracy3 = m.result()  # m.total/m.count\n",
        "print(\"accuracy3=\", accuracy3.numpy())\n",
        "\n",
        "#6\n",
        "#6-1\n",
        "m = tf.keras.metrics.Precision()\n",
        "m.update_state(y_true, y_pred)\n",
        "print(\"m.true_positives=\", m.true_positives.numpy())\n",
        "print(\"m.false_positives\", m.false_positives.numpy())\n",
        "print(\"precision=\", m.result().numpy())\n",
        "\n",
        "#6-2\n",
        "m = tf.keras.metrics.Recall()\n",
        "m.update_state(y_true, y_pred)\n",
        "print(\"m.true_positives=\", m.true_positives.numpy())\n",
        "print(\"m.false_negatives\", m.false_negatives.numpy())\n",
        "print(\"recall=\", m.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFuzJHXQ5jUr",
        "outputId": "3fc2c6e6-9eff-4a0f-d2cd-9eb8d84f3ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m.total=12.0, m.count=18.0\n",
            "accuracy3= 0.6666667\n",
            "m.true_positives= [3.]\n",
            "m.false_positives [3.]\n",
            "precision= 0.5\n",
            "m.true_positives= [3.]\n",
            "m.false_negatives [3.]\n",
            "recall= 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### p.129"
      ],
      "metadata": {
        "id": "jPmVEoQbDVed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#1\n",
        "##y_true = np.array([0, 1, 2, 0, 1, 2])\n",
        "##y_true = tf.keras.utils.to_categorical(y_true) # one-hot\n",
        "y_true = np.array([[1, 0, 0], #0\n",
        "                   [0, 1, 0], #1\n",
        "                   [0, 0, 1], #2\n",
        "                   [1, 0, 0], #0\n",
        "                   [0, 1, 0], #1\n",
        "                   [0, 0, 1]]);#2\n",
        "\n",
        "y_pred = np.array([[0.3, 0.6, 0.1],  #1,\n",
        "                   [0.6, 0.3, 0.1],  #0\n",
        "                   [0.1, 0.3, 0.6],  #2\n",
        "                   [0.3, 0.6, 0.1],  #1\n",
        "                   [0.1, 0.6, 0.3],  #1\n",
        "                   [0.3, 0.1, 0.6]]);#2\n",
        "num_class = y_true.shape[1] # 3\n",
        "\n",
        "#2: C and TOP_k\n",
        "#2-1: threshold, and C in # 3-1, #4-1, and #6 in [step1701]\n",
        "y_true1 = np.argmax(y_true, axis=1).flatten()\n",
        "y_pred1 = np.argmax(np.cast['int'](y_pred>0.5), axis=1).flatten()\n",
        "C = tf.math.confusion_matrix(y_true1, y_pred1)\n",
        "print(\"y_true1=\",y_true1) # y_true1= [0 1 2 0 1 2]\n",
        "print(\"y_pred1=\",y_pred1) # y_pred1= [1 0 2 1 1 2]\n",
        "print(\"confusion_matrix(C)=\", C)\n",
        "\n",
        "#2-2: to find top-k index, in #3-2, #4-2\n",
        "k=2\n",
        "indx = tf.argsort(y_pred, axis=1, direction='DESCENDING')\n",
        "TOP_k = indx[:,:k]\n",
        "print(\"TOP_k = \", TOP_k)\n",
        "\n",
        "#3\n",
        "print(\"In each class, precision!\")\n",
        "#3-1: binary(1 above threshold=0.5, 0 below threshold= 0.5)\n",
        "for i in range(num_class):\n",
        "    m = tf.keras.metrics.Precision(class_id = i)\n",
        "    m.update_state(y_true, y_pred)\n",
        "    tp = m.true_positives.numpy()\n",
        "    fp = m.false_positives.numpy()\n",
        "    p = m.result().numpy()\n",
        "    print(\" p_{} ={}, tp={}, fp= {}\".format(i,p, tp, fp))\n",
        "\n",
        "#3-2: the top-k classes with the highest predicted values\n",
        "print(\"In each class, precision with top_k=\", k)\n",
        "for i in range(num_class):\n",
        "    m = tf.keras.metrics.Precision(top_k=k, class_id = i)\n",
        "    m.update_state(y_true, y_pred)\n",
        "    tp = m.true_positives.numpy()\n",
        "    fp = m.false_positives.numpy()\n",
        "    p = m.result().numpy()\n",
        "    print(\" p_{} ={}, tp={}, fp= {}\".format(i,p, tp, fp))\n",
        "#4\n",
        "print(\"In each class, recall!\")\n",
        "#4-1: binary(1 above threshold=0.5, 0 below threshold= 0.5)\n",
        "for i in range(num_class):\n",
        "    m = tf.keras.metrics.Recall(class_id = i)\n",
        "    m.update_state(y_true, y_pred)\n",
        "    tp = m.true_positives.numpy()\n",
        "    fn = m.false_negatives.numpy()\n",
        "    r = m.result().numpy()\n",
        "    print(\" recall_{} ={}, tp={}, fn= {}\".format(i,r, tp, fn))\n",
        "\n",
        "#4-2: the top-k classes with the highest predicted values\n",
        "print(\"In each class, recall with top_k=\", k)\n",
        "for i in range(num_class):\n",
        "    m = tf.keras.metrics.Recall(top_k=k, class_id = i)\n",
        "    m.update_state(y_true, y_pred)\n",
        "    r = m.result().numpy()\n",
        "    print(\" recall_{} ={}, tp={}, fn= {}\".format(i,r, tp, fn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHab1sAsC2nD",
        "outputId": "a55dec5e-8ddf-49cc-dd1b-387414e55d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_true1= [0 1 2 0 1 2]\n",
            "y_pred1= [1 0 2 1 1 2]\n",
            "confusion_matrix(C)= tf.Tensor(\n",
            "[[0 2 0]\n",
            " [1 1 0]\n",
            " [0 0 2]], shape=(3, 3), dtype=int32)\n",
            "TOP_k =  tf.Tensor(\n",
            "[[1 0]\n",
            " [0 1]\n",
            " [2 1]\n",
            " [1 0]\n",
            " [1 2]\n",
            " [2 0]], shape=(6, 2), dtype=int32)\n",
            "In each class, precision!\n",
            " p_0 =0.0, tp=[0.], fp= [1.]\n",
            " p_1 =0.3333333432674408, tp=[1.], fp= [2.]\n",
            " p_2 =1.0, tp=[2.], fp= [0.]\n",
            "In each class, precision with top_k= 2\n",
            " p_0 =0.5, tp=[2.], fp= [2.]\n",
            " p_1 =0.4000000059604645, tp=[2.], fp= [3.]\n",
            " p_2 =0.6666666865348816, tp=[2.], fp= [1.]\n",
            "In each class, recall!\n",
            " recall_0 =0.0, tp=[0.], fn= [2.]\n",
            " recall_1 =0.5, tp=[1.], fn= [1.]\n",
            " recall_2 =1.0, tp=[2.], fn= [0.]\n",
            "In each class, recall with top_k= 2\n",
            " recall_0 =1.0, tp=[2.], fn= [0.]\n",
            " recall_1 =1.0, tp=[2.], fn= [0.]\n",
            " recall_2 =1.0, tp=[2.], fn= [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### p.132"
      ],
      "metadata": {
        "id": "pMQz1NpbDZ5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#1\n",
        "y_true = np.array([0, 1, 2, 0, 1, 2])\n",
        "y_pred = np.array([1, 0, 2, 1, 1, 2])\n",
        "\n",
        "#2\n",
        "m = tf.keras.metrics.Accuracy()\n",
        "m.update_state(y_true, y_pred)  #m.count = 3, m.total=6\n",
        "print(\"accuracy from f.keras.metrics.Accuracy()=\", m.result().numpy() )\n",
        "\n",
        "#3\n",
        "C = tf.math.confusion_matrix(y_true, y_pred)\n",
        "print(\"confusion_matrix=\", C)\n",
        "\n",
        "correct = tf.linalg.diag_part(C)\n",
        "col_sum = tf.reduce_sum(C, axis=0)\n",
        "row_sum = tf.reduce_sum(C, axis=1)\n",
        "total   = tf.reduce_sum(C)  #  len(y_true), len(y_pred)\n",
        "\n",
        "accuracy    = tf.reduce_sum(correct)/total\n",
        "precision_i = correct/col_sum\n",
        "recall_i    = correct/row_sum\n",
        "f1_i = 2*(precision_i*recall_i)/(precision_i+recall_i) # harmonic mean of precision and recall\n",
        "f1_i = tf.where(tf.math.is_nan(f1_i), tf.zeros_like(f1_i), f1_i) # nan to 0.0\n",
        "print(\"accuracy=\",    accuracy.numpy())\n",
        "print(\"precision_i=\", precision_i.numpy())\n",
        "print(\"recall_i=\",    recall_i.numpy())\n",
        "print(\"f1_i=\",    f1_i.numpy())\n",
        "\n",
        "#4:  micro, macro, weighted avg in precision, recall\n",
        "tp = tf.reduce_sum(correct)    # notice : correct pairs such as (0,0), (1,1), (2,2)\n",
        "fp = tf.reduce_sum(col_sum - correct) # in this case, fp == fn\n",
        "fn = tf.reduce_sum(row_sum - correct)\n",
        "precision = tp/(tp + fp)\n",
        "recall    = tp/(tp + fn)\n",
        "\n",
        "count = tf.math.bincount(y_true) # support  in sklearn.metrics\n",
        "print(\"count =\", count)\n",
        "print(\"precision(micro avg)=\", precision.numpy())\n",
        "print(\"precision(macro avg)=\", tf.reduce_sum(precision_i)/precision_i.shape[0])\n",
        "w=  tf.cast(count, dtype = tf.float64)/y_true.shape[0]  # tf.cast(total, dtype = tf.float64)\n",
        "weightedAvgP = tf.reduce_sum(precision_i*w)\n",
        "print(\"precision(weighted avg)=\", weightedAvgP)\n",
        "\n",
        "print(\"recall(micro avg)=\", recall.numpy())\n",
        "print(\"recall(macro avg)=\", tf.reduce_sum(recall_i)/recall_i.shape[0])\n",
        "weightedAvgR = tf.reduce_sum(recall_i*w)\n",
        "print(\"recall(weighted avg)=\", weightedAvgR)\n",
        "\n",
        "#5: pip install sklearn\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score,precision_score, recall_score\n",
        "print(\"--- sklearn.metrics ---\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "print(\"accuracy=\", accuracy_score(y_true, y_pred)) # normalize=True\n",
        "print(\"precision_i=\", precision_score(y_true, y_pred, average=None))\n",
        "print(\"precision(micro avg)=\", precision_score(y_true, y_pred, average='micro'))\n",
        "print(\"precision(macro avg)=\", precision_score(y_true, y_pred, average='macro'))\n",
        "\n",
        "print(\"recall_i=\", recall_score(y_true, y_pred, average=None))\n",
        "print(\"recall(micro avg)=\", recall_score(y_true, y_pred, average='micro'))\n",
        "print(\"recall(macro avg)=\", recall_score(y_true, y_pred, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7z1olwaDJe3",
        "outputId": "01e24675-784e-474d-80f8-7b7b69dfa40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy from f.keras.metrics.Accuracy()= 0.5\n",
            "confusion_matrix= tf.Tensor(\n",
            "[[0 2 0]\n",
            " [1 1 0]\n",
            " [0 0 2]], shape=(3, 3), dtype=int32)\n",
            "accuracy= 0.5\n",
            "precision_i= [0.         0.33333333 1.        ]\n",
            "recall_i= [0.  0.5 1. ]\n",
            "f1_i= [0.  0.4 1. ]\n",
            "count = tf.Tensor([2 2 2], shape=(3,), dtype=int32)\n",
            "precision(micro avg)= 0.5\n",
            "precision(macro avg)= tf.Tensor(0.4444444444444444, shape=(), dtype=float64)\n",
            "precision(weighted avg)= tf.Tensor(0.4444444444444444, shape=(), dtype=float64)\n",
            "recall(micro avg)= 0.5\n",
            "recall(macro avg)= tf.Tensor(0.5, shape=(), dtype=float64)\n",
            "recall(weighted avg)= tf.Tensor(0.5, shape=(), dtype=float64)\n",
            "--- sklearn.metrics ---\n",
            "[[0 2 0]\n",
            " [1 1 0]\n",
            " [0 0 2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.33      0.50      0.40         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.50         6\n",
            "   macro avg       0.44      0.50      0.47         6\n",
            "weighted avg       0.44      0.50      0.47         6\n",
            "\n",
            "accuracy= 0.5\n",
            "precision_i= [0.         0.33333333 1.        ]\n",
            "precision(micro avg)= 0.5\n",
            "precision(macro avg)= 0.4444444444444444\n",
            "recall_i= [0.  0.5 1. ]\n",
            "recall(micro avg)= 0.5\n",
            "recall(macro avg)= 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### p.135"
      ],
      "metadata": {
        "id": "FbloG-MWDe6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#1\n",
        "##y_true = np.array([0, 1, 2, 0, 1, 2])\n",
        "##y_true = tf.keras.utils.to_categorical(y_true) # one-hot\n",
        "y_true = np.array([[1, 0, 0], #0\n",
        "                   [0, 1, 0], #1\n",
        "                   [0, 0, 1], #2\n",
        "                   [1, 0, 0], #0\n",
        "                   [0, 1, 0], #1\n",
        "                   [0, 0, 1]], dtype=np.int32);#2\n",
        "\n",
        "y_pred = np.array([[0.3, 0.6, 0.1], #1\n",
        "                   [0.6, 0.3, 0.1], #0\n",
        "                   [0.1, 0.3, 0.6], #2\n",
        "                   [0.3, 0.6, 0.1], #1\n",
        "                   [0.1, 0.6, 0.3], #1\n",
        "                   [0.3, 0.1, 0.6]], dtype=np.float32);#2\n",
        "\n",
        "print(y_true.dtype)\n",
        "print(y_pred.dtype)\n",
        "\n",
        "#2: using one-hot encoding in y_true\n",
        "print(\"CategoricalAccuracy!\")\n",
        "\n",
        "#2-1\n",
        "accuracy2_1= tf.keras.metrics.categorical_accuracy(y_true, y_pred)\n",
        "print(\"accuracy2_1=\", accuracy2_1.numpy())\n",
        "#2-2\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m.update_state(y_true, y_pred)\n",
        "# m.total = tf.reduce_sum(accuracy2_1)\n",
        "# m.count = accuracy2_1.shape[0]\n",
        "accuracy2_2 = m.result() # m.total/m.count\n",
        "print(\"m.total={}, m.count={}\".format(m.total.numpy(),m.count.numpy()))\n",
        "print(\"accuracy2_2=\", accuracy2_2.numpy())\n",
        "\n",
        "#2-3\n",
        "top_k = 2\n",
        "accuracy2_3 = tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=top_k)\n",
        "print(\"top_k={}, accuracy2_3={}\".format(top_k, accuracy2_3))\n",
        "\n",
        "#2-4\n",
        "m = tf.keras.metrics.TopKCategoricalAccuracy(k=top_k) # default k = 5\n",
        "m.update_state(y_true, y_pred)\n",
        "# m.total = tf.reduce_sum(accuracy2_3)\n",
        "# m.count = accuracy2_3.shape[0]\n",
        "accuracy2_4 = m.result()\n",
        "print(\"m.total={}, m.count={}\".format(m.total.numpy(),m.count.numpy()))\n",
        "print(\"top_k={}, accuracy2_4={}\".format(top_k, accuracy2_4.numpy()))\n",
        "\n",
        "#3: using integer label in y_true\n",
        "print(\"SparseCategoricalAccuracy!\")\n",
        "y_true = tf.argmax(y_true, axis = 1) # np.argmax(y_true, axis = 1)\n",
        "y_true = tf.reshape(y_true, (-1,1))  # np.reshape(y_true, (-1, 1))\n",
        "print(\"y_true=\", y_true)\n",
        "\n",
        "#3-1\n",
        "accuracy3_1= tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "print(\"accuracy3_1=\", accuracy3_1.numpy())\n",
        "#3-2\n",
        "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "m.update_state(y_true, y_pred)\n",
        "# m.total = tf.reduce_sum(accuracy3_1)\n",
        "# m.count = accuracy3_1.shape[0]\n",
        "accuracy3_2 = m.result() # m.total/m.count\n",
        "print(\"m.total={}, m.count={}\".format(m.total.numpy(),m.count.numpy()))\n",
        "print(\"accuracy3_2=\", accuracy3_2.numpy())\n",
        "\n",
        "#3-3\n",
        "top_k = 2\n",
        "accuracy3_3 = tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=top_k)\n",
        "print(\"top_k={}, accuracy3_3={}\".format(top_k, accuracy3_3))\n",
        "\n",
        "#3-4\n",
        "m = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=top_k) # default k = 5\n",
        "m.update_state(y_true, y_pred)\n",
        "# m.total = tf.reduce_sum(accuracy3_3)\n",
        "# m.count = accuracy3_3.shape[0]\n",
        "accuracy3_4 = m.result()\n",
        "print(\"m.total={}, m.count={}\".format(m.total.numpy(),m.count.numpy()))\n",
        "print(\"top_k={}, accuracy3_4={}\".format(top_k, accuracy3_4.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR3Ytcz6DLw5",
        "outputId": "0acd767c-07b1-441c-a195-5105b6474fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int32\n",
            "float32\n",
            "CategoricalAccuracy!\n",
            "accuracy2_1= [0. 0. 1. 0. 1. 1.]\n",
            "m.total=3.0, m.count=6.0\n",
            "accuracy2_2= 0.5\n",
            "top_k=2, accuracy2_3=[1. 1. 1. 1. 1. 1.]\n",
            "m.total=6.0, m.count=6.0\n",
            "top_k=2, accuracy2_4=1.0\n",
            "SparseCategoricalAccuracy!\n",
            "y_true= tf.Tensor(\n",
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [1]\n",
            " [2]], shape=(6, 1), dtype=int64)\n",
            "accuracy3_1= [0. 0. 1. 0. 1. 1.]\n",
            "m.total=3.0, m.count=6.0\n",
            "accuracy3_2= 0.5\n",
            "top_k=2, accuracy3_3=[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "m.total=6.0, m.count=6.0\n",
            "top_k=2, accuracy3_4=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxSyctd8Z46I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}